# Production Docker Compose for VisLang-UltraLow-Resource
version: '3.8'

services:
  # Main application with multiple replicas for load balancing
  vislang-app:
    image: terragonlabs/vislang-ultralow:${VERSION:-latest}
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - LOG_LEVEL=INFO
      - METRICS_ENABLED=true
      - SENTRY_DSN=${SENTRY_DSN}
      - API_BASE_URL=${API_BASE_URL}
    volumes:
      - vislang-cache:/app/cache
      - vislang-models:/app/models:ro
      - ./config:/app/config:ro
    networks:
      - vislang-network
    depends_on:
      - postgres
      - redis
      - minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nginx load balancer and reverse proxy
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - vislang-static:/var/www/static:ro
    networks:
      - vislang-network
    depends_on:
      - vislang-app
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure

  # PostgreSQL database with replication
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-vislang}
      POSTGRES_USER: ${POSTGRES_USER:-vislang}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --locale=C"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d:ro
    networks:
      - vislang-network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-vislang}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and session storage
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - vislang-network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # MinIO for object storage (models, datasets, cache)
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_BROWSER_REDIRECT_URL: ${MINIO_BROWSER_REDIRECT_URL}
    volumes:
      - minio-data:/data
    networks:
      - vislang-network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - vislang-network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - vislang-network
    depends_on:
      - prometheus
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  # Elasticsearch for log aggregation
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - vislang-network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.0
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    networks:
      - vislang-network
    depends_on:
      - elasticsearch
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  # Logstash for log processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./monitoring/logstash/config:/usr/share/logstash/config:ro
    networks:
      - vislang-network
    depends_on:
      - elasticsearch
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  # Backup service for data protection
  backup:
    image: postgres:15-alpine
    environment:
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - backup-data:/backup
      - ./scripts:/scripts:ro
    networks:
      - vislang-network
    command: |
      sh -c "
        while true; do
          pg_dump -h postgres -U ${POSTGRES_USER:-vislang} ${POSTGRES_DB:-vislang} > /backup/backup_$$(date +%Y%m%d_%H%M%S).sql
          find /backup -name '*.sql' -mtime +7 -delete
          sleep 86400
        done
      "
    depends_on:
      - postgres
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

networks:
  vislang-network:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.0.10.0/24

volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  minio-data:
    driver: local
  vislang-cache:
    driver: local
  vislang-models:
    driver: local
  vislang-static:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  elasticsearch-data:
    driver: local
  backup-data:
    driver: local

# Secrets for production deployment
secrets:
  postgres_password:
    external: true
  redis_password:
    external: true
  minio_password:
    external: true
  jwt_secret:
    external: true
  api_keys:
    external: true

# Configuration for production deployment
configs:
  nginx_config:
    file: ./nginx/nginx.conf
  prometheus_config:
    file: ./monitoring/prometheus.yml
  grafana_config:
    file: ./monitoring/grafana/grafana.ini